{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216c9ae0",
   "metadata": {},
   "source": [
    "# Instructions to get 1 game of SET scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Arrow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.path as mplPath\n",
    "from shapely.geometry import Polygon as PolygonArea\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import os\n",
    "from itertools import chain\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.spatial import Voronoi,voronoi_plot_2d, ConvexHull\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.path as mplPath\n",
    "from shapely.geometry import Polygon as PolygonArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dae485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the week that the game is\n",
    "week_number = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the plays.csv provided\n",
    "plays = pd.read_csv('/content/drive/MyDrive/NFL DATA BOWL/plays.csv',None)\n",
    "#enter the tracking week you wish to look at\n",
    "week_df = pd.read_csv(f'/content/drive/MyDrive/NFL DATA BOWL/tracking_week_{week_number}.csv',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7210277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'los_x' from 'week_df' where 'displayName' is 'football' and 'frameId' is 1\n",
    "los_x = week_df[(week_df['displayName'] == 'football') & (week_df['frameId'] == 1)][['gameId', 'playId', 'x']].rename(columns={'x': 'los_x'})\n",
    "# Merge 'los_x' back into 'week_df'\n",
    "week_df = week_df.merge(los_x, on=['gameId', 'playId'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for some future variables we use, standardized angle, etc\n",
    "\n",
    "result_df['ToLeft'] = 0\n",
    "result_df['ToLeft'] = result_df['playDirection'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "\n",
    "result_df['YardsFromOwnGoal'] = result_df[['yardlineSide','possessionTeam','yardlineNumber']].apply(lambda row:row.yardlineNumber if row.yardlineSide==row.possessionTeam else 50+(50-row.yardlineNumber), axis=1)\n",
    "\n",
    "result_df['YardsFromOwnGoal'] = result_df[['YardsFromOwnGoal','yardlineNumber']].apply(lambda row:50 if row.yardlineNumber==50 else row.YardsFromOwnGoal, axis=1)\n",
    "\n",
    "result_df['X_std'] = result_df[['ToLeft','x']].apply(lambda row:120-row.x-10 if row.ToLeft else row.x-10, axis=1)\n",
    "\n",
    "result_df['Y_std'] = result_df[['ToLeft','y']].apply(lambda row:160/3-row.y if row.ToLeft else row.y, axis=1)\n",
    "\n",
    "result_df['Dir_std_1'] = result_df[['ToLeft','dir']].apply(lambda row:row.dir+360 if (row.ToLeft and row.dir<90) else row.dir, axis=1)\n",
    "result_df['Dir_std_1'] = result_df[['ToLeft','dir','Dir_std_1']].apply(lambda row:row.dir-360 if ((not row.ToLeft) and row.dir>270) else row.Dir_std_1, axis=1)\n",
    "result_df['Dir_std_2'] = result_df[['ToLeft','Dir_std_1']].apply(lambda row:row.Dir_std_1-180 if row.ToLeft else row.Dir_std_1, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'displayName' and 'ballCarrierDisplayName' are columns in result_df\n",
    "result_df['ballcarrier'] = np.where(result_df['displayName'] == result_df['ballCarrierDisplayName'], 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854685cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to put players.csv provided in order to get position by player\n",
    "position = pd.read_csv('/content/drive/MyDrive/NFL DATA BOWL/players.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61734a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.merge(position, on=['nflId'], how='left')\n",
    "result_df = result_df.rename(columns={'displayName_x': 'displayName'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ada10",
   "metadata": {},
   "source": [
    "# Which runs qualify for the SET Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fe12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_run_qualify(tracking_for_play):\n",
    "    qualifies = 0\n",
    "\n",
    "    filtered_df = tracking_for_play[(tracking_for_play['ballcarrier'] == 1) & (tracking_for_play['frameId'] == 1)]\n",
    "    if not filtered_df.empty:\n",
    "        offense_club = filtered_df['club'].iloc[0]\n",
    "    else:\n",
    "        print(\"NO TEAM GIVEN\")\n",
    "        return\n",
    "\n",
    "    los = tracking_for_play[(tracking_for_play['displayName'] == 'football') & (tracking_for_play['frameId'] == 1)]\n",
    "    los_x = los['x'].iloc[0]\n",
    "\n",
    "    behind_los_frames = []\n",
    "    for index, row in tracking_for_play.iterrows():\n",
    "        if row['playDirection'] == 'right' and row['displayName'] == 'football':\n",
    "            if row['x'] < los_x:\n",
    "                behind_los_frames.append(row['frameId'])\n",
    "        elif row['playDirection'] == 'left' and row['displayName'] == 'football':\n",
    "            if row['x'] > los_x:\n",
    "                behind_los_frames.append(row['frameId'])\n",
    "\n",
    "    try:\n",
    "        last_frame_behind_los = max(behind_los_frames)\n",
    "    except ValueError:\n",
    "        print(\"ODDITY\", row['playId'])\n",
    "        return\n",
    "\n",
    "    behind_los_tracking = tracking_for_play[tracking_for_play['frameId'] <= last_frame_behind_los]\n",
    "\n",
    "    tackles = behind_los_tracking[(behind_los_tracking['position'] == 'T') & (behind_los_tracking['frameId'] == 1)]\n",
    "    tackles_y = tackles['y'].to_list()\n",
    "    print(tackles_y)\n",
    "\n",
    "    if len(tackles_y) == 1:\n",
    "        guards = behind_los_tracking[(behind_los_tracking['position'] == 'G') & (behind_los_tracking['frameId'] == 1)]\n",
    "        guards_y = guards['y'].to_list()\n",
    "        tackles_y.append(guards_y)\n",
    "        tackles_y = [item for sublist in tackles_y for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    if len(tackles_y) == 0:\n",
    "      print(\"ODDITY\", row['playId'])\n",
    "      return\n",
    "\n",
    "    for index, row in behind_los_tracking.iterrows():\n",
    "        if row['ballcarrier'] == 1:\n",
    "            x, y, direction, speed = row[\"x\"], row[\"y\"], row[\"dir\"], row[\"s\"]\n",
    "            adjusted_direction = np.mod(90 - direction, 360)\n",
    "            x_comp = np.cos(np.radians(adjusted_direction))\n",
    "            y_comp = np.sin(np.radians(adjusted_direction))\n",
    "            v_x = speed * x_comp\n",
    "            v_y = speed * y_comp\n",
    "            mu_val_x = x + v_x * 0.5\n",
    "            mu_val_y = y + v_y * 0.5\n",
    "            mu = [mu_val_x, mu_val_y]\n",
    "            min_tackle_value = min(tackles_y)\n",
    "            max_tackle_value = max(tackles_y)\n",
    "            is_between = min_tackle_value <= mu_val_y <= max_tackle_value\n",
    "\n",
    "            if not is_between:\n",
    "                qualifies = 1\n",
    "                break\n",
    "\n",
    "    return qualifies\n",
    "\n",
    "# Iterate over games and plays\n",
    "def check_all_runs(results_df):\n",
    "    results = []\n",
    "\n",
    "    for game_id in results_df['gameId'].unique():\n",
    "        game_data = results_df[results_df['gameId'] == game_id]\n",
    "\n",
    "        for play_id in game_data['playId'].unique():\n",
    "            play_data = game_data[game_data['playId'] == play_id]\n",
    "            qualifies = does_run_qualify(play_data)\n",
    "            results.append({'gameId': game_id, 'playId': play_id, 'Qualifies': qualifies})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "#final_results_df is going to be the runs which qualify for the score\n",
    "final_results_df = check_all_runs(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff27ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.merge(final_results_df, on=['gameId', 'playId'])\n",
    "#make a new dataframe of all the qualified runs\n",
    "qualified = result_df[result_df['Qualifies']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e67057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine which direction the runner was intending to go\n",
    "def left_or_right_run_intention(week7_tracking_runs_qualified, game_id, play_id):\n",
    "\n",
    "    tracking_for_play = week7_tracking_runs_qualified[(week7_tracking_runs_qualified['gameId'] == game_id) & (week7_tracking_runs_qualified['playId'] == play_id)]\n",
    "\n",
    "    threshold_tracking = tracking_for_play[(tracking_for_play['frameId'] <= 25) & (tracking_for_play['ballcarrier'] == 1)]\n",
    "\n",
    "    ballcarrier_dirs = []\n",
    "\n",
    "    for index, row in threshold_tracking.iterrows():\n",
    "        ballcarrier_dirs.append(row['Dir_std_2'])\n",
    "\n",
    "    left_count = sum(0 <= angle <= 90 for angle in ballcarrier_dirs)\n",
    "    right_count = sum(90 < angle <= 180 for angle in ballcarrier_dirs)\n",
    "\n",
    "    intended_direction = \"\"\n",
    "\n",
    "    if left_count > right_count:\n",
    "        intended_direction += \"left\"\n",
    "    elif right_count > left_count:\n",
    "        intended_direction += \"right\"\n",
    "\n",
    "    return intended_direction\n",
    "\n",
    "#determine who the edge setter is on each play \n",
    "from collections import Counter\n",
    "def edge_setter_in_question(runs_that_qualify, game_id, play_id):\n",
    "\n",
    "    tracking_for_play = runs_that_qualify[(runs_that_qualify['gameId'] == game_id) & (runs_that_qualify['playId'] == play_id)]\n",
    "\n",
    "    los = tracking_for_play[(tracking_for_play['displayName'] == 'football') & (tracking_for_play['frameId'] == 1)]\n",
    "    los_x = los['X_std'].iloc[0]\n",
    "\n",
    "    positions = [\"CB\", \"DB\", \"DE\", \"OLB\"]\n",
    "\n",
    "    ballcarrier_tracking_frames = tracking_for_play[tracking_for_play['ballcarrier'] == 1]\n",
    "    target_tracking = tracking_for_play[(tracking_for_play['position'].isin(positions)) | (tracking_for_play['ballcarrier'] == 1)]\n",
    "\n",
    "    ### GIVES US LOS FRAME\n",
    "    mask = ballcarrier_tracking_frames['X_std'] > los_x\n",
    "\n",
    "    first_valid_index = ballcarrier_tracking_frames[mask].first_valid_index()\n",
    "\n",
    "    end_frame = ballcarrier_tracking_frames.loc[first_valid_index, 'frameId'] if first_valid_index is not None else None\n",
    "\n",
    "    if end_frame is None:\n",
    "        first_contact_index = ballcarrier_tracking_frames[ballcarrier_tracking_frames['event'] == 'first_contact'].first_valid_index()\n",
    "        end_frame = ballcarrier_tracking_frames.loc[first_contact_index, 'frameId'] if first_contact_index is not None else ballcarrier_tracking_frames['frameId'].max()\n",
    "\n",
    "    target_tracking = target_tracking[target_tracking['frameId'] <= end_frame]\n",
    "    ballcarrier_tracking_filtered = ballcarrier_tracking_frames[ballcarrier_tracking_frames['frameId'] <= end_frame]\n",
    "\n",
    "    ballcarrier_data = ballcarrier_tracking_filtered.copy()\n",
    "    ballcarrier_data['x_comp'] = np.cos(np.radians(ballcarrier_data['Dir_std_2']))\n",
    "    ballcarrier_data['y_comp'] = np.sin(np.radians(ballcarrier_data['Dir_std_2']))\n",
    "    ballcarrier_data['v_x'] = ballcarrier_data['s'] * ballcarrier_data['x_comp']\n",
    "    ballcarrier_data['v_y'] = ballcarrier_data['s'] * ballcarrier_data['y_comp']\n",
    "    ballcarrier_data['mu_val_x'] = ballcarrier_data['X_std'] + ballcarrier_data['v_x'] * 0.5\n",
    "    ballcarrier_data['mu_val_y'] = ballcarrier_data['Y_std'] + ballcarrier_data['v_y'] * 0.5\n",
    "\n",
    "    closest_defenders = {}\n",
    "\n",
    "    for frame_id in ballcarrier_data['frameId'].unique():\n",
    "        # Ball carrier's target point for this frame\n",
    "        bx = ballcarrier_data.loc[ballcarrier_data['frameId'] == frame_id, 'mu_val_x'].iloc[0]\n",
    "        by = ballcarrier_data.loc[ballcarrier_data['frameId'] == frame_id, 'mu_val_y'].iloc[0]\n",
    "\n",
    "        # Filter for defenders in the same frame\n",
    "        frame_defenders = target_tracking[(target_tracking['frameId'] == frame_id) & (target_tracking['ballcarrier'] != 1)].copy()\n",
    "\n",
    "        # Vectorized distance calculation\n",
    "        frame_defenders['distance_to_target'] = np.sqrt((frame_defenders['X_std'] - bx) ** 2 + (frame_defenders['Y_std'] - by) ** 2)\n",
    "\n",
    "        if not frame_defenders.empty:\n",
    "            closest_defender = frame_defenders.loc[frame_defenders['distance_to_target'].idxmin()]\n",
    "            closest_defenders[frame_id] = closest_defender['displayName']\n",
    "\n",
    "        else:\n",
    "            closest_defenders[frame_id] = None\n",
    "\n",
    "    name_counter = Counter(closest_defenders.values())\n",
    "\n",
    "    edge_rusher = name_counter.most_common(1)[0][0]\n",
    "    return edge_rusher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991522d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the functions to qualified\n",
    "def analyze_runs_in_qualified(qualified):\n",
    "    results = []\n",
    "\n",
    "    for game_id in qualified['gameId'].unique():\n",
    "        game_data = qualified[qualified['gameId'] == game_id]\n",
    "\n",
    "        for play_id in game_data['playId'].unique():\n",
    "            play_data = game_data[game_data['playId'] == play_id]\n",
    "\n",
    "            # Call your functions for each game and play\n",
    "            run_intention = left_or_right_run_intention(qualified, game_id, play_id)\n",
    "            edge_rusher = edge_setter_in_question(qualified, game_id, play_id)\n",
    "\n",
    "            # Store the results\n",
    "            results.append({'gameId': game_id, 'playId': play_id, 'RunIntention': run_intention, 'EdgeRusher': edge_rusher})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "final_analysis_df = analyze_runs_in_qualified(qualified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the new functions back into qualified\n",
    "qualified = qualified.merge(final_analysis_df, on=['gameId', 'playId'])\n",
    "#now qualified will be used going forward, I'd reccomend saving this to re open later, up to the user though"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0576ba5",
   "metadata": {},
   "source": [
    "# Creation of the Overlap variable - the major aspect in the SET score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb98751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The overlap variable is the overlap between the Defenders Voronoi Regions and the ballcarrier's valuable space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FUNCTION TO CREATE FOOTBALL FIELD\n",
    "\n",
    "def create_football_field():\n",
    "\n",
    "    # Create a rectangle defined via an anchor point *xy* and its *width* and *height*\n",
    "    rect = patches.Rectangle((0, 0), 120, 53.3, facecolor='green', alpha = 0.7, zorder=0)\n",
    "\n",
    "    # Creating a subplot to plot our field on\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 6.33))\n",
    "\n",
    "    # Adding the rectangle to the plot\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Plotting a line plot for marking the field lines\n",
    "    #plt.plot([10, 10, 20, 20, 30, 30, 40, 40, 50, 50, 60, 60, 70, 70, 80,\n",
    "              #80, 90, 90, 100, 100, 110, 110, 120, 0, 0, 120, 120],\n",
    "             #[0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3,\n",
    "             # 0, 0, 53.3, 53.3, 0, 0, 53.3, 53.3, 53.3, 0, 0, 53.3],\n",
    "             #color='white', zorder = 0)\n",
    "\n",
    "    # Creating the left end-zone\n",
    "    left_end_zone = patches.Rectangle((0, 0), 10, 53.3, facecolor='blue', alpha=0.2, zorder=0)\n",
    "\n",
    "    # Creating the right end-zone\n",
    "    right_end_zone = patches.Rectangle((110, 0), 120, 53.3, facecolor='blue', alpha=0.2, zorder=0)\n",
    "\n",
    "    # Adding the patches to the subplot\n",
    "    ax.add_patch(left_end_zone)\n",
    "    ax.add_patch(right_end_zone)\n",
    "\n",
    "    # Setting the limits of x-axis from 0 to 120\n",
    "    #plt.xlim(0, 120)\n",
    "\n",
    "    # Setting the limits of y-axis from -5 to 58.3\n",
    "    #plt.ylim(-5, 58.3)\n",
    "\n",
    "    # Removing the axis values from the plot\n",
    "    #plt.axis('off')\n",
    "\n",
    "    # Plotting the numbers starting from x = 20 and ending at x = 110\n",
    "    # with a step of 10\n",
    "    for x in range(20, 110, 10):\n",
    "\n",
    "        # Intializing another variable named 'number'\n",
    "        number = x\n",
    "\n",
    "        # If x exceeds 50, subtract it from 120\n",
    "        if x > 50:\n",
    "            number = 120 - x\n",
    "\n",
    "        # Plotting the text at the bottom\n",
    "        plt.text(x, 5, str(number - 10),\n",
    "                 horizontalalignment='center',\n",
    "                 fontsize=20,\n",
    "                 color='white')\n",
    "\n",
    "        # Plotting the text at the top\n",
    "        plt.text(x - 0.95, 53.3 - 5, str(number - 10),\n",
    "                 horizontalalignment='center',\n",
    "                 fontsize=20,\n",
    "                 color='white',\n",
    "                 rotation=180)\n",
    "\n",
    "    # Making ground markings\n",
    "    for x in range(11, 110):\n",
    "            ax.plot([x, x], [0.4, 0.7], color='white', zorder = 0)\n",
    "            ax.plot([x, x], [53.0, 52.5], color='white', zorder = 0)\n",
    "            ax.plot([x, x], [22.91, 23.57], color='white', zorder = 0)\n",
    "            ax.plot([x, x], [29.73, 30.39], color='white', zorder = 0)\n",
    "\n",
    "    # Returning the figure and axis\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def calculate_voronoi_regions(player_coordinates):\n",
    "    vor = Voronoi(player_coordinates)\n",
    "\n",
    "    voronoi_regions = []\n",
    "\n",
    "    for r in range(len(player_coordinates)):\n",
    "        region = vor.regions[vor.point_region[r]]\n",
    "        if not -1 in region:\n",
    "            polygon_coords = [vor.vertices[i] for i in region]\n",
    "            voronoi_regions.append(polygon_coords)\n",
    "\n",
    "    return voronoi_regions\n",
    "#these are the coordinates of the voronoi regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68380119",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking = qualified.copy()\n",
    "ballcarrier = tracking[tracking['ballcarrier']==1]\n",
    "ballcarrier = ballcarrier.rename(columns={col: f'ballcarrier_{col}' for col in ballcarrier.columns})\n",
    "# Create a subset of 'ballcarrier' with only the necessary columns\n",
    "ballcarrier_subset = ballcarrier[['ballcarrier_gameId', 'ballcarrier_playId','ballcarrier_frameId', 'ballcarrier_s', 'ballcarrier_x']]\n",
    "\n",
    "#merge this back into tracking as it allows for ballcarrier information to be in the same row as all players\n",
    "tracking = tracking.merge(ballcarrier_subset, left_on=['gameId', 'playId', 'frameId'], right_on=['ballcarrier_gameId', 'ballcarrier_playId', 'ballcarrier_frameId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bba8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our metric cannot be run on frames where the ballcarrier speed is not above 0 \n",
    "tracking['speed_metric'] = (tracking['ballcarrier_s'] > 0).astype(int)\n",
    "\n",
    "# Sort DataFrame by playId and then by frameId\n",
    "tracking = tracking.sort_values(by=['playId', 'frameId'])\n",
    "\n",
    "# Identify where speed_metric goes from 1 to 0, this step is needed for ballcarrier's in motion pre snap\n",
    "tracking['speed_drops_to_zero'] = (tracking['speed_metric'] == 0) & (tracking['speed_metric'].shift(1) == 1)\n",
    "\n",
    "# Group by playId and find the first occurrence of speed dropping to 0 in each play\n",
    "first_drop_indices = tracking.groupby('playId')['speed_drops_to_zero'].transform('idxmax')\n",
    "\n",
    "# Create a mask to keep rows after the first drop to zero in each play\n",
    "mask = tracking.index >= first_drop_indices\n",
    "\n",
    "# Apply the mask to filter the DataFrame\n",
    "tracking = tracking[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ad0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calculate if the ballcarrier is past the LOS in each frame\n",
    "tracking['is_past_threshold'] = np.where(\n",
    "    ((tracking['playDirection'] == 'right') & (tracking['ballcarrier_x'] > tracking['los_x'])) |\n",
    "    ((tracking['playDirection'] == 'left') & (tracking['ballcarrier_x'] < tracking['los_x'])),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Use cummax to ensure that once the LOS is passed, it remains passed for all subsequent frames\n",
    "tracking['past_threshold'] = tracking.groupby(['gameId', 'playId'])['is_past_threshold'].cummax()\n",
    "tracking= tracking[tracking['past_threshold']==0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap = mpl.colormaps['viridis']\n",
    "\n",
    "data_for_dataframe = []\n",
    "cumulative_overlap_dict = {}\n",
    "\n",
    "# THIS IS JUST THE FUNCTION - use of this function is later\n",
    "\n",
    "def calculate_overlap_for_frame(frame_id, game_id, play_id, tracking, cumulative_dict):\n",
    "\n",
    "    tracking_all = tracking[(tracking['playId'] == play_id)\n",
    "                                 & (tracking['gameId'] == game_id)\n",
    "                                 & (tracking['frameId'] == frame_id)]\n",
    "\n",
    "    tracking_all = tracking_all.sort_values(by='club')\n",
    "    tracking_all_no_football = tracking_all[tracking_all['club'] != 'football']\n",
    "\n",
    "    # FOR GRAIENT COLORING ON PROB. DISTRIBUTION FUNCTION\n",
    "\n",
    "    x, y = np.mgrid[0:120:1, 0:53.3:1]\n",
    "    locations = np.dstack((x, y))\n",
    "    x, y = np.mgrid[0:120:1, 0:53.3:1]\n",
    "    fig, ax = create_football_field()\n",
    "\n",
    "\n",
    "    ballcarrier = tracking_all[tracking_all['ballcarrier'] == 1]\n",
    "    offensive_team = ballcarrier['club'].to_list()[0]\n",
    "\n",
    "\n",
    "\n",
    "    offensive_data = tracking_all[(tracking_all['frameId'] == frame_id) & (tracking_all['club'] == offensive_team)]\n",
    "    defense_data = tracking_all[(tracking_all['frameId'] == frame_id) & (tracking_all['club'] != offensive_team) & (tracking_all['club'] != 'football')]\n",
    "    football_data = tracking_all[(tracking_all['frameId'] == frame_id) & (tracking_all['club'] == 'football')]\n",
    "\n",
    "    offensive_x, offensive_y = offensive_data['x'], offensive_data['y']\n",
    "    defense_x, defense_y = defense_data['x'], defense_data['y']\n",
    "    football_x, football_y = football_data['x'], football_data['y']\n",
    "\n",
    "    xy = tracking_all_no_football[['x','y']].values\n",
    "\n",
    "    n_points = xy.shape[0]\n",
    "    xy1 = xy.copy()\n",
    "    xy1[:,1] = - xy[:,1]\n",
    "    xy2 = xy.copy()\n",
    "    xy2[:,1] = 320/3 - xy[:,1]\n",
    "    xy3 = xy.copy()\n",
    "    xy3[:,0] = 30 - xy[:,0]\n",
    "    xy4 = xy.copy()\n",
    "    xy4[:,0] = 220 - xy[:,0]\n",
    "    xy = np.concatenate((xy, xy1, xy2, xy3, xy4), axis=0)\n",
    "\n",
    "    voronoi_regions1 = calculate_voronoi_regions(xy)\n",
    "\n",
    "    num_regions = len(voronoi_regions1)\n",
    "    colors = ['red'] * 11 + ['lightblue'] * (11)\n",
    "\n",
    "    polygons = [Polygon(region) for region in voronoi_regions1]\n",
    "\n",
    "    plot = PatchCollection(polygons, facecolors = colors, alpha=0.35)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    for index, row in ballcarrier.iterrows():\n",
    "\n",
    "        x, y, direction, speed = row[\"x\"], row[\"y\"], row[\"dir\"], row[\"s\"]\n",
    "        ballcarrier_x = row['x']\n",
    "        ballcarrier_y = row['y']\n",
    "\n",
    "        speed_ratio = (speed**2)/(100)\n",
    "\n",
    "        adjusted_direction = np.mod(90 - direction, 360)  # Apply the adjustment\n",
    "\n",
    "        x_comp = np.cos(np.radians(adjusted_direction))\n",
    "        y_comp = np.sin(np.radians(adjusted_direction))\n",
    "\n",
    "        v_x = speed * x_comp\n",
    "        v_y = speed * y_comp\n",
    "\n",
    "        arrow = Arrow(x, y, v_x, v_y, width=1, color='white', zorder=2)\n",
    "\n",
    "        scaling_matrix = np.diag([abs(v_x), abs(v_y)])\n",
    "\n",
    "        if 215 < adjusted_direction < 315 or 45 < adjusted_direction < 135:\n",
    "\n",
    "            rotation_matrix = np.array([[np.cos(np.radians(adjusted_direction - 90)), -np.sin(np.radians(adjusted_direction - 90))],\n",
    "                                       [np.sin(np.radians(adjusted_direction - 90)), np.cos(np.radians(adjusted_direction - 90))]])\n",
    "\n",
    "            rotation_matrix_T = rotation_matrix.T\n",
    "\n",
    "            covariance_matrix = rotation_matrix @ scaling_matrix @ rotation_matrix_T\n",
    "\n",
    "        else:\n",
    "\n",
    "            rotation_matrix = np.array([[np.cos(np.radians(adjusted_direction)), -np.sin(np.radians(adjusted_direction))],\n",
    "                                       [np.sin(np.radians(adjusted_direction)), np.cos(np.radians(adjusted_direction))]])\n",
    "\n",
    "            rotation_matrix_T = rotation_matrix.T\n",
    "\n",
    "            covariance_matrix = rotation_matrix @ scaling_matrix @ rotation_matrix_T\n",
    "            covariance_matrix += np.eye(covariance_matrix.shape[0]) * 1e-8\n",
    "\n",
    "        mu_val_x = x + v_x * 0.5\n",
    "        mu_val_y = y + v_y * 0.5\n",
    "        mu = [mu_val_x,mu_val_y]\n",
    "\n",
    "        player_pdf = multivariate_normal(mu,covariance_matrix).pdf(locations)\n",
    "\n",
    "        player_pdf_df = pd.DataFrame(data=player_pdf)\n",
    "\n",
    "        player_pdf_values = player_pdf_df.values\n",
    "        new_cmap = LinearSegmentedColormap.from_list('custom_cmap', ['green', 'green'])\n",
    "\n",
    "\n",
    "        #normalized_player_pdf_values = (player_pdf_values - np.min(player_pdf_values)) / (np.max(player_pdf_values) - np.min(player_pdf_values))\n",
    "\n",
    "        x, y = np.mgrid[0:120:1, 0:53.3:1]\n",
    "        exact_contour_filled = ax.contourf(x, y, player_pdf_values, cmap=new_cmap, levels=1, zorder=2)\n",
    "        viz_contour_filled = ax.contourf(x, y, player_pdf_values, cmap=new_cmap, levels=25, zorder=2)\n",
    "\n",
    "\n",
    "        #football_scatter = ax.scatter(football_x, football_y, c='brown', edgecolors='white', alpha=0.75, linewidth=0.75, s=40, zorder=3)\n",
    "        voronoi_player_dict = {}\n",
    "\n",
    "        n_players = min(len(tracking_all_no_football['displayName']), 22)\n",
    "        n_regions = min(len(voronoi_regions1), 22)\n",
    "\n",
    "        for player, region in zip(tracking_all_no_football['displayName'][:n_players], voronoi_regions1[:n_regions]):\n",
    "            voronoi_player_dict[player] = region\n",
    "\n",
    "        defense_players_list = defense_data['displayName'].to_list()\n",
    "\n",
    "        voronoi_player_dict_defense = {}\n",
    "\n",
    "        for key, value in voronoi_player_dict.items():\n",
    "            if key in defense_players_list:\n",
    "                voronoi_player_dict_defense[key] = value\n",
    "\n",
    "        voronoi_player_dict_defense_clean = {player: [array.tolist() for array in regions]\n",
    "                                         for player, regions in voronoi_player_dict_defense.items()}\n",
    "\n",
    "        values = voronoi_player_dict_defense_clean.values()\n",
    "        list_vals = list(values)\n",
    "\n",
    "        for verts in list_vals:\n",
    "            for cord in verts:\n",
    "                x, y = cord\n",
    "                ax.scatter(x, y, c='white', s=10)\n",
    "\n",
    "\n",
    "        contour_path = exact_contour_filled.collections[0].get_paths()[0]\n",
    "        countour_vertices = contour_path.vertices\n",
    "        countour_vertices_list = countour_vertices.tolist()\n",
    "\n",
    "        countour_cleaned_vertices = []\n",
    "\n",
    "        for pair in countour_vertices_list:\n",
    "            if len(str(pair[0])) > 5 or len(str(pair[1])) > 5:\n",
    "                countour_cleaned_vertices.append(pair)\n",
    "\n",
    "        countour_polygon = PolygonArea(countour_cleaned_vertices)\n",
    "        #print(countour_polygon.area)\n",
    "        data_for_dataframe = []\n",
    "        for key, value in voronoi_player_dict_defense_clean.items():\n",
    "            voronoi_polygon = PolygonArea(value)\n",
    "            intersection = countour_polygon.intersection(voronoi_polygon)\n",
    "\n",
    "            overlap_area = intersection.area\n",
    "            overlap_percentage = (overlap_area / countour_polygon.area) * 100  # Assuming percentage calculation\n",
    "\n",
    "            # Update cumulative_dict\n",
    "            cumulative_dict[key] = cumulative_dict.get(key, 0) + overlap_percentage\n",
    "\n",
    "            # Prepare data for the DataFrame\n",
    "            data_for_dataframe.append([game_id, play_id, frame_id, key, overlap_percentage])\n",
    "\n",
    "    return data_for_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure to select the game_id in which you want the SET scores for\n",
    "\n",
    "desired_segment_df = tracking[tracking['game_id']==game_id]\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def process_frame(frame_id, game_id, play_id, tracking):\n",
    "    try:\n",
    "        frame_data = calculate_overlap_for_frame(frame_id, game_id, play_id, tracking, cumulative_overlap_dict)\n",
    "        return frame_data\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'game_id': game_id,\n",
    "            'play_id': play_id,\n",
    "            'frame_id': frame_id,\n",
    "            'error_message': str(e),\n",
    "            'type': 'error'\n",
    "        }\n",
    "\n",
    "# Assuming all_data is a list\n",
    "all_data = []\n",
    "\n",
    "# Adjust the number of workers based on your system's capabilities\n",
    "num_workers = 4\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    futures = []\n",
    "    total_frames = 0\n",
    "\n",
    "    #MAKE SURE TO ENTER THE game_id \n",
    "        single_game = tracking[tracking['gameId'] == game_id]\n",
    "\n",
    "        for play_id in single_game['playId'].unique():\n",
    "            single_play = single_game[single_game['playId'] == play_id]\n",
    "            frame_max = single_play['frameId'].max()\n",
    "            frame_min = single_play['frameId'].min()\n",
    "\n",
    "            for frame_id in range(frame_min, frame_max + 1):\n",
    "                futures.append(executor.submit(process_frame, frame_id, game_id, play_id, tracking))\n",
    "                total_frames += 1\n",
    "\n",
    "    completed_frames = 0\n",
    "    # Incremental collection of results with progress tracking\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        completed_frames += 1\n",
    "\n",
    "        if isinstance(result, list):\n",
    "            all_data.extend(result)\n",
    "        else:\n",
    "            all_data.append(result)\n",
    "\n",
    "        print(f\"Completed {completed_frames}/{total_frames} frames\")\n",
    "\n",
    "    print(\"All frames processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['gameId', 'playId', 'frameId', 'playerName', 'overlapPercentage']\n",
    "overlap_df = pd.DataFrame(all_data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming overlap_df and qualified are already defined\n",
    "#Make sure qualified is the same as the point earlier where I said to save it\n",
    "\n",
    "# Step 1: Check data types\n",
    "print(\"Data types in overlap_df:\")\n",
    "print(overlap_df[['gameId', 'playId', 'frameId', 'playerName']].dtypes)\n",
    "print(\"\\nData types in qualified:\")\n",
    "print(qualified[['gameId', 'playId', 'frameId', 'displayName']].dtypes)\n",
    "\n",
    "# Step 2: Convert data types if necessary\n",
    "# Example: If 'gameId' is int in one DataFrame and string in another, convert both to string\n",
    "overlap_df['gameId'] = combined_df['gameId'].astype(str)\n",
    "qualified['gameId'] = qualified['gameId'].astype(str)\n",
    "\n",
    "# Do the same for 'playId', 'frameId', and rename 'displayName' to 'playerName' in 'qualified'\n",
    "overlap_df['playId'] = combined_df['playId'].astype(str)\n",
    "qualified['playId'] = qualified['playId'].astype(str)\n",
    "\n",
    "overlap_df['frameId'] = combined_df['frameId'].astype(str)\n",
    "qualified['frameId'] = qualified['frameId'].astype(str)\n",
    "\n",
    "qualified_renamed = qualified.rename(columns={'displayName': 'playerName'})\n",
    "\n",
    "# Step 3: Perform the merge\n",
    "merged_df = pd.merge(overlap_df, qualified_renamed, how='left', on=['gameId', 'playId', 'frameId', 'playerName'])\n",
    "#SET score only applies to 3 positions, OLB, CB, and DE\n",
    "filtered_df = merged_df[merged_df['position'].isin(['OLB', 'CB', 'DE'])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4677bb",
   "metadata": {},
   "source": [
    "# Other features that are part of the SET score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7005ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'overlapPercentage' to numeric\n",
    "filtered_df['overlapPercentage'] = pd.to_numeric(filtered_df['overlapPercentage'], errors='coerce')\n",
    "\n",
    "# Calculate the cumulative overlap\n",
    "cumulative_overlap = filtered_df.groupby(['gameId', 'playId', 'playerName'])['overlapPercentage'].sum().reset_index()\n",
    "cumulative_overlap = cumulative_overlap.rename(columns={'overlapPercentage': 'cumulativeOverlap'})\n",
    "\n",
    "# Rank players within each gameId and playId based on the cumulativeOverlap\n",
    "cumulative_overlap['overlapRank'] = cumulative_overlap.groupby(['gameId', 'playId'])['cumulativeOverlap'].rank(ascending=False, method='first')\n",
    "\n",
    "# Merge the rankings back into the original filtered_df\n",
    "# Merge, ensuring each player in each play gets their new rank\n",
    "filtered_df = pd.merge(filtered_df, cumulative_overlap[['gameId', 'playId', 'playerName', 'cumulativeOverlap', 'overlapRank']], on=['gameId', 'playId', 'playerName'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda92d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring back qualified again and assign it to the new variable, nonf\n",
    "nonf = qualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db300df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is used to determine the intended direction of the ballcarrier while also noting the endzone they're approaching\n",
    "\n",
    "nonf['right_left'] = nonf.apply(lambda x: 1 if x['playDirection'] == 'right' and x['RunIntention'] == 'left' else 0, axis=1)\n",
    "nonf['right_right'] = nonf.apply(lambda x: 1 if x['playDirection'] == 'right' and x['RunIntention'] == 'right' else 0, axis=1)\n",
    "nonf['left_right'] = nonf.apply(lambda x: 1 if x['playDirection'] == 'left' and x['RunIntention'] == 'right' else 0, axis=1)\n",
    "nonf['left_left'] = nonf.apply(lambda x: 1 if x['playDirection'] == 'left' and x['RunIntention'] == 'left' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these steps are used to calculate another part of our SET score, which is angle change of the ballcarrier\n",
    "\n",
    "# Step 1: Create a DataFrame for ballcarrier\n",
    "ballcarrier_df = nonf[nonf['ballcarrier'] == 1].copy()\n",
    "\n",
    "# Step 2: Calculate ballcarrier_direction_1 and ballcarrier_direction_2\n",
    "# ballcarrier_direction_1\n",
    "ballcarrier_df['ballcarrier_direction_1'] = ballcarrier_df.apply(\n",
    "    lambda row: row.dir + 360 if (row.ToLeft and row.dir < 90) else row.dir,\n",
    "    axis=1)\n",
    "\n",
    "# Adjust ballcarrier_direction_1\n",
    "ballcarrier_df['ballcarrier_direction_1'] = ballcarrier_df.apply(\n",
    "    lambda row: row.dir - 360 if ((not row.ToLeft) and row.dir > 270) else row.ballcarrier_direction_1,\n",
    "    axis=1)\n",
    "\n",
    "# ballcarrier_direction_2\n",
    "ballcarrier_df['ballcarrier_direction_2'] = ballcarrier_df.apply(\n",
    "    lambda row: row.ballcarrier_direction_1 - 180 if row.ToLeft else row.ballcarrier_direction_1,\n",
    "    axis=1)\n",
    "\n",
    "#ballcarrier y coordinate in 5 frames\n",
    "\n",
    "ballcarrier_df['y_in_5_frames'] = ballcarrier_df.groupby(['gameId', 'playId'])['y'].shift(-5)\n",
    "ballcarrier_df['direction_in_5_frames'] = ballcarrier_df.groupby(['gameId', 'playId'])['ballcarrier_direction_2'].shift(-5)\n",
    "ballcarrier_df['difference'] = ballcarrier_df['direction_in_5_frames']-ballcarrier_df['ballcarrier_direction_2']\n",
    "\n",
    "def calculate_good_job(row):\n",
    "    if (row['left_left'] == 1 or row['right_left'] == 1) and row['difference'] > 0:\n",
    "        return 1  # Set to 1 for positive difference in left left/right left\n",
    "    elif (row['left_right'] == 1 or row['right_right'] == 1) and row['difference'] < 0:\n",
    "        return 1  # Set to 1 for negative difference in left right/right right\n",
    "    else:\n",
    "        return 0  # Default case\n",
    "\n",
    "# Apply the function to create the new column\n",
    "ballcarrier_df['good_job'] = ballcarrier_df.apply(calculate_good_job, axis=1)\n",
    "\n",
    "#Merge the new columns back into the original DataFrame 'nonf'\n",
    "# Selecting only the relevant columns for merge\n",
    "ballcarrier_df = ballcarrier_df.add_prefix('ballcarrier_')\n",
    "\n",
    "\n",
    "columns_to_merge = ['ballcarrier_gameId', 'ballcarrier_playId', 'ballcarrier_frameId', 'ballcarrier_x', 'ballcarrier_y','ballcarrier_y_in_5_frames','ballcarrier_difference','ballcarrier_direction_in_5_frames','ballcarrier_ballcarrier_direction_2','ballcarrier_good_job']\n",
    "\n",
    "nonf = pd.merge(nonf, ballcarrier_df[columns_to_merge],\n",
    "                left_on=['gameId', 'playId', 'frameId'],\n",
    "                right_on=['ballcarrier_gameId', 'ballcarrier_playId', 'ballcarrier_frameId'],\n",
    "                how='left')\n",
    "\n",
    "# Optionally, you can drop the redundant gameId, playId, and frameId columns from ballcarrier_df if they exist\n",
    "nonf.drop(columns=['ballcarrier_gameId', 'ballcarrier_playId', 'ballcarrier_frameId'], inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8597437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step is another feature of our score\n",
    "#it has to do with whether or not the ballcarrier ends up outside of the edge defender\n",
    "#if the ballcarrier ends up outside, we set the score to zero, as the edge was not set properly\n",
    "\n",
    "def is_inside(row):\n",
    "    # Check the play direction based on specific columns\n",
    "    if row.left_right == 1 or row.right_left == 1:\n",
    "        return 1 if row.y < row.ballcarrier_y_in_5_frames else 0\n",
    "    elif row.left_left == 1 or row.right_right == 1:\n",
    "        return 1 if row.y > row.ballcarrier_y_in_5_frames else 0\n",
    "    else:\n",
    "        return 0  # Default case if no play direction is specified\n",
    "\n",
    "# Apply the function to each row in nonf\n",
    "nonf['is_inside'] = nonf.apply(is_inside, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53453f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in the tackles.csv provided\n",
    "\n",
    "tackles = pd.read_csv('path here',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming nonf and tackles are your DataFrames\n",
    "# Step 1: Check and convert data types\n",
    "# Convert gameId, playId, and nflId to string in both DataFrames (formatting gets messed up without this step)\n",
    "nonf['gameId'] = nonf['gameId'].astype(str)\n",
    "nonf['playId'] = nonf['playId'].astype(str)\n",
    "nonf['nflId'] = nonf['nflId'].astype(str)\n",
    "\n",
    "tackles['gameId'] = tackles['gameId'].astype(str)\n",
    "tackles['playId'] = tackles['playId'].astype(str)\n",
    "tackles['nflId'] = tackles['nflId'].astype(str)\n",
    "\n",
    "# Step 2: Perform the merge, this will allow us to see which player made the tackle\n",
    "nonf = pd.merge(nonf, tackles[['gameId', 'playId', 'nflId', 'tackle']],\n",
    "                on=['gameId', 'playId', 'nflId'],\n",
    "                how='left')\n",
    "\n",
    "# Replace NaN in the 'tackle' column with 0\n",
    "nonf['tackle'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert 'tackle' to integer\n",
    "nonf['tackle'] = nonf['tackle'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the dataframe only contains the players with the highest overlap on each play, we only give one score per play\n",
    "only1 = filtered_df[filtered_df['overlapRank']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170eabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the week variable is still correct\n",
    "only1['week'] = week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d177cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming only1 and nonf are your DataFrames\n",
    "\n",
    "# Step 1: Check data types and convert if necessary\n",
    "# Convert gameId, playId, and frameId to string if they are not already\n",
    "only1['gameId'] = only1['gameId'].astype(str)\n",
    "only1['playId'] = only1['playId'].astype(str)\n",
    "only1['frameId'] = only1['frameId'].astype(str)\n",
    "nonf['gameId'] = nonf['gameId'].astype(str)\n",
    "nonf['playId'] = nonf['playId'].astype(str)\n",
    "nonf['frameId'] = nonf['frameId'].astype(str)\n",
    "\n",
    "# Also ensure playerName and displayName are of the same type\n",
    "only1['playerName'] = only1['playerName'].astype(str)\n",
    "nonf['displayName'] = nonf['displayName'].astype(str)\n",
    "\n",
    "# Step 2: Perform the merge\n",
    "merged_df = pd.merge(only1, nonf, left_on=['gameId', 'playId', 'frameId', 'playerName'],\n",
    "                     right_on=['gameId', 'playId', 'frameId', 'displayName'], how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986140e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the change in ballcarrier angle standarized into a decimal\n",
    "merged_df['standardized_difference'] = abs(merged_df['ballcarrier_difference']/90)\n",
    "\n",
    "\n",
    "# Convert 'overlapPercentage' to numeric, coerce any non-numeric values to NaN\n",
    "merged_df['overlapPercentage'] = pd.to_numeric(merged_df['overlapPercentage'], errors='coerce')\n",
    "\n",
    "# Create the 'is_overlap' column based on whether 'overlapPercentage' is greater than 0\n",
    "# NaN values will be treated as False in this comparison\n",
    "merged_df['is_overlap'] = (merged_df['overlapPercentage'] > 0).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872129d",
   "metadata": {},
   "source": [
    "# Creation of the SET metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where the set score is created\n",
    "merged_df['set_score'] = ((merged_df['overlapPercentage']/100) + merged_df['standardized_difference'])/2 * merged_df['ballcarrier_good_job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c13a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a metric to see whether or not the edge setter was successful in setting the edge, it's binary\n",
    "only_overlap = merged_df[merged_df['is_overlap']==1]\n",
    "only_overlap['successful'] = only_overlap.apply(lambda row: 1 if row['is_overlap'] == 1 and row['set_score'] != 0 else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1676cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the groupby and aggregation\n",
    "stats_df = only_overlap.groupby(['gameId', 'playId', 'playerName']).agg({\n",
    "    'set_score': ['sum', 'mean'],\n",
    "    'position_x': 'first',\n",
    "    'expectedPointsAdded_x': 'first',\n",
    "    'passProbability_x': 'first',\n",
    "    'playResult_x': 'first',\n",
    "    'overlapPercentage':'first',\n",
    "    'standardized_difference':'first',\n",
    "    'tackle':'first',\n",
    "    'successful':'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "stats_df.columns = ['_'.join(col).strip('_') for col in stats_df.columns.values]\n",
    "\n",
    "# Rename the columns for clarity\n",
    "stats_df.rename(columns={\n",
    "    'set_tackle_sum': 'cumulative_set_tackle',\n",
    "    'set_tackle_mean': 'average_set_tackle',\n",
    "    'position_x_first': 'position_x',\n",
    "    'epa_first': 'expectedPointsAdded_x',\n",
    "    'pass_probability_x_first': 'passProbability_x',\n",
    "    'playResult_x_first': 'playResult_x',\n",
    "    'successful_first':'successful'\n",
    "}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step takes the old set_score and adds in the tackle factor, to award players for making the play\n",
    "\n",
    "\n",
    "# Function to modify set_score_sum and set_score_mean based on tackle_first\n",
    "def modify_scores(row):\n",
    "    if row['tackle_first'] == 1:\n",
    "        row['set_score_sum_incl_tackle'] = row['set_score_sum'] + 0.5\n",
    "        row['set_score_mean_incl_tackle'] = row['set_score_mean'] + 0.5\n",
    "    else:\n",
    "        row['set_score_sum_incl_tackle'] = row['set_score_sum']\n",
    "        row['set_score_mean_incl_tackle'] = row['set_score_mean']\n",
    "    return row\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "stats_df = stats_df.apply(modify_scores, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997df20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = stats_df.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = stats_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Define aggregation logic\n",
    "aggregation_logic = {col: 'first' for col in categorical_cols if col != 'playerName'}  # Keep first value for categorical columns, except 'playerName'\n",
    "aggregation_logic.update({col: 'mean' for col in numerical_cols if col not in ['cumulative_set_tackle', 'set_score_sum_incl_tackle', 'set_score_mean_incl_tackle']})  # Average for numerical, except specified columns\n",
    "\n",
    "aggregation_logic['set_score_sum_incl_tackle'] = 'sum'  # Sum for 'set_score_sum_incl_tackle'\n",
    "aggregation_logic['set_score_mean_incl_tackle'] = 'mean'  # Mean for 'set_score_mean_incl_tackle'\n",
    "\n",
    "# Add a column to count the number of plays per 'gameId' and 'playerName' group\n",
    "stats_df['num_plays'] = stats_df.groupby(['gameId', 'playerName'])['playId'].transform('nunique')\n",
    "aggregation_logic['num_plays'] = 'first'  # Keep the first value of num_plays, which is the same for all rows in the group\n",
    "\n",
    "# Group by 'gameId' and 'playerName', then apply aggregation\n",
    "grouped_df = stats_df.groupby(['gameId', 'playerName'], as_index=False).agg(aggregation_logic)\n",
    "\n",
    "# Display the DataFrame\n",
    "grouped_df = grouped_df.sort_values(by='set_score_sum_incl_tackle', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a82306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of successful plays\n",
    "grouped_df['successful plays'] = grouped_df['num_plays'] * grouped_df['successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save grouped_df as a csv and view it, the SET score should be complete\n",
    "#the tackle SET score is the version we chose to use in our work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332bf67",
   "metadata": {},
   "source": [
    "# Note these cells are if you are looping through multiple games, percentile doesn't make sense if there isn't a large enough sample size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming grouped_df is your DataFrame\n",
    "\n",
    "# Function to scale percentile rank to 1-99 range\n",
    "def scale_percentile(series):\n",
    "    percentile_rank = series.rank(pct=True)  # Calculate percentile rank\n",
    "    scaled_percentile = percentile_rank * 99  # Scale to 99 instead of 100\n",
    "    return scaled_percentile.round().clip(lower=1)  # Round and clip to ensure the range is 1 to 99\n",
    "\n",
    "# Calculate scaled percentile for 'cumulative_set_tackle'\n",
    "grouped_df['cumulative_set_tackle_percentile'] = (grouped_df['set_score_sum_incl_tackle'].rank(pct=True) * 100).round()\n",
    "\n",
    "# Calculate scaled percentile for 'average_set_tackle'\n",
    "grouped_df['average_set_tackle_percentile'] = (grouped_df['set_score_mean_incl_tackle'].rank(pct=True) * 100).round()\n",
    "\n",
    "# Calculate the absolute value of 'standardized_difference_first'\n",
    "grouped_df['standardized_difference_first_abs'] = grouped_df['standardized_difference_first'].abs()\n",
    "\n",
    "# Calculate scaled percentile for 'overlapPercentage_first'\n",
    "grouped_df['overlapPercentage_percentile'] = scale_percentile(grouped_df['overlapPercentage_first'])\n",
    "\n",
    "# Calculate scaled percentile for the absolute value of 'standardized_difference_first'\n",
    "grouped_df['standardized_difference_percentile'] = scale_percentile(grouped_df['standardized_difference_first_abs'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c74b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming grouped_df is your DataFrame\n",
    "# Assuming the percentile column for cumulative percent is named 'cumulative_set_tackle_percentile'\n",
    "\n",
    "# Filter and get top 10 for CB\n",
    "top10_CB = grouped_df[grouped_df['position_x'] == 'CB'].nlargest(25, 'cumulative_set_tackle_percentile')\n",
    "\n",
    "# Filter and get top 10 for OLB\n",
    "top10_OLB = grouped_df[grouped_df['position_x'] == 'OLB'].nlargest(25, 'cumulative_set_tackle_percentile')\n",
    "\n",
    "# Filter and get top 10 for DE\n",
    "top10_DE = grouped_df[grouped_df['position_x'] == 'DE'].nlargest(25, 'cumulative_set_tackle_percentile')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401022a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is when looping through multiple games"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
